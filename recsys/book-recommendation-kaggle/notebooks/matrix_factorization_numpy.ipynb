{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Matrix Factorization with NumPy/SciPy\n",
                "\n",
                "Pure numpy implementation of matrix factorization for book recommendations. We'll decompose the user-book rating matrix U √ó B and use book similarities based on user rating patterns."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "from scipy.sparse import csr_matrix\n",
                "from scipy.sparse.linalg import svds\n",
                "from sklearn.metrics.pairwise import cosine_similarity\n",
                "from sklearn.decomposition import NMF\n",
                "import matplotlib.pyplot as plt\n",
                "import wandb\n",
                "import warnings\n",
                "warnings.filterwarnings('ignore')\n",
                "\n",
                "DATA_DIR = \"../data\""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Initialize wandb\n",
                "run = wandb.init(\n",
                "    project=\"book-recommendation-kaggle\",\n",
                "    group=\"matrix-factorization-numpy\",\n",
                "    job_type=\"train\",\n",
                "    save_code=True,\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Data Loading and Preprocessing"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load data\n",
                "print(\"Loading data...\")\n",
                "books = pd.read_csv(f\"{DATA_DIR}/Books.csv.zip\", compression=\"zip\")\n",
                "ratings = pd.read_csv(f\"{DATA_DIR}/Ratings.csv.zip\", compression=\"zip\")\n",
                "users = pd.read_csv(f\"{DATA_DIR}/Users.csv.zip\", compression=\"zip\")\n",
                "\n",
                "print(f\"Books: {len(books):,}\")\n",
                "print(f\"Ratings: {len(ratings):,}\")\n",
                "print(f\"Users: {len(users):,}\")\n",
                "\n",
                "# Show rating distribution\n",
                "print(f\"\\nRating distribution:\")\n",
                "print(ratings['Book-Rating'].value_counts().sort_index())"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Filter for users and books with at least 5 interactions\n",
                "print(\"\\n=== Filtering for Active Users and Popular Books ===\")\n",
                "\n",
                "min_interactions = 5\n",
                "\n",
                "# Count interactions\n",
                "user_counts = ratings.groupby('User-ID').size()\n",
                "book_counts = ratings.groupby('ISBN').size()\n",
                "\n",
                "# Filter\n",
                "active_users = user_counts[user_counts >= min_interactions].index\n",
                "popular_books = book_counts[book_counts >= min_interactions].index\n",
                "\n",
                "print(f\"Active users (‚â•{min_interactions} ratings): {len(active_users):,} / {len(user_counts):,}\")\n",
                "print(f\"Popular books (‚â•{min_interactions} ratings): {len(popular_books):,} / {len(book_counts):,}\")\n",
                "\n",
                "# Filter ratings to active users and popular books\n",
                "filtered_ratings = ratings[\n",
                "    (ratings['User-ID'].isin(active_users)) & \n",
                "    (ratings['ISBN'].isin(popular_books))\n",
                "].copy()\n",
                "\n",
                "print(f\"Filtered ratings: {len(filtered_ratings):,} / {len(ratings):,} ({len(filtered_ratings)/len(ratings)*100:.1f}%)\")\n",
                "\n",
                "# Sample for faster computation if dataset is too large\n",
                "max_users = 10000  # Limit for computational efficiency\n",
                "max_books = 5000\n",
                "\n",
                "if len(active_users) > max_users:\n",
                "    # Sample most active users\n",
                "    top_users = user_counts.nlargest(max_users).index\n",
                "    filtered_ratings = filtered_ratings[filtered_ratings['User-ID'].isin(top_users)]\n",
                "    print(f\"Sampled to top {max_users:,} most active users\")\n",
                "\n",
                "if len(popular_books) > max_books:\n",
                "    # Sample most popular books\n",
                "    top_books = book_counts.nlargest(max_books).index\n",
                "    filtered_ratings = filtered_ratings[filtered_ratings['ISBN'].isin(top_books)]\n",
                "    print(f\"Sampled to top {max_books:,} most popular books\")\n",
                "\n",
                "print(f\"Final filtered ratings: {len(filtered_ratings):,}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create compact indices\n",
                "print(\"\\n=== Creating User-Book Rating Matrix ===\")\n",
                "\n",
                "# Get unique users and books from filtered data\n",
                "unique_users = sorted(filtered_ratings['User-ID'].unique())\n",
                "unique_books = sorted(filtered_ratings['ISBN'].unique())\n",
                "\n",
                "# Create mappings\n",
                "user_to_idx = {user_id: idx for idx, user_id in enumerate(unique_users)}\n",
                "book_to_idx = {book_id: idx for idx, book_id in enumerate(unique_books)}\n",
                "idx_to_user = {idx: user_id for user_id, idx in user_to_idx.items()}\n",
                "idx_to_book = {idx: book_id for book_id, idx in book_to_idx.items()}\n",
                "\n",
                "# Map to indices\n",
                "filtered_ratings['user_idx'] = filtered_ratings['User-ID'].map(user_to_idx)\n",
                "filtered_ratings['book_idx'] = filtered_ratings['ISBN'].map(book_to_idx)\n",
                "\n",
                "n_users = len(unique_users)\n",
                "n_books = len(unique_books)\n",
                "\n",
                "print(f\"Matrix dimensions: {n_users:,} users √ó {n_books:,} books\")\n",
                "print(f\"Total possible ratings: {n_users * n_books:,}\")\n",
                "print(f\"Actual ratings: {len(filtered_ratings):,}\")\n",
                "print(f\"Sparsity: {(1 - len(filtered_ratings) / (n_users * n_books)) * 100:.2f}%\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create book metadata mapping\n",
                "print(\"\\n=== Creating Book Metadata ===\")\n",
                "\n",
                "# Filter books metadata to only those in our dataset\n",
                "book_metadata = books[books['ISBN'].isin(unique_books)].copy()\n",
                "book_metadata['book_idx'] = book_metadata['ISBN'].map(book_to_idx)\n",
                "\n",
                "# Create title mappings\n",
                "title_to_idx = {}\n",
                "idx_to_title = {}\n",
                "idx_to_author = {}\n",
                "\n",
                "for _, row in book_metadata.iterrows():\n",
                "    book_idx = row['book_idx']\n",
                "    title = row['Book-Title']\n",
                "    author = row['Book-Author']\n",
                "    \n",
                "    title_to_idx[title] = book_idx\n",
                "    idx_to_title[book_idx] = title\n",
                "    idx_to_author[book_idx] = author\n",
                "\n",
                "print(f\"Book metadata for {len(book_metadata):,} books\")\n",
                "\n",
                "# Show sample books\n",
                "print(\"\\nSample books:\")\n",
                "for i, (_, row) in enumerate(book_metadata.head(5).iterrows()):\n",
                "    print(f\"  {row['Book-Title']} by {row['Book-Author']}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Create Rating Matrix"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Build the user-book rating matrix\n",
                "print(\"\\n=== Building Rating Matrix ===\")\n",
                "\n",
                "# Create sparse matrix\n",
                "user_indices = filtered_ratings['user_idx'].values\n",
                "book_indices = filtered_ratings['book_idx'].values\n",
                "rating_values = filtered_ratings['Book-Rating'].values.astype(np.float32)\n",
                "\n",
                "# Create sparse rating matrix (users x books)\n",
                "rating_matrix = csr_matrix(\n",
                "    (rating_values, (user_indices, book_indices)), \n",
                "    shape=(n_users, n_books),\n",
                "    dtype=np.float32\n",
                ")\n",
                "\n",
                "print(f\"Rating matrix shape: {rating_matrix.shape}\")\n",
                "print(f\"Non-zero entries: {rating_matrix.nnz:,}\")\n",
                "print(f\"Density: {rating_matrix.nnz / (n_users * n_books) * 100:.3f}%\")\n",
                "print(f\"Memory usage: {rating_matrix.data.nbytes + rating_matrix.indices.nbytes + rating_matrix.indptr.nbytes} bytes\")\n",
                "\n",
                "# Convert to dense for small matrices (if feasible)\n",
                "matrix_size_mb = (n_users * n_books * 4) / (1024**2)  # 4 bytes per float32\n",
                "print(f\"Dense matrix would be: {matrix_size_mb:.1f} MB\")\n",
                "\n",
                "if matrix_size_mb < 500:  # Only convert if less than 500MB\n",
                "    print(\"Converting to dense matrix for easier manipulation...\")\n",
                "    rating_matrix_dense = rating_matrix.toarray()\n",
                "    use_dense = True\n",
                "else:\n",
                "    print(\"Keeping sparse matrix due to size\")\n",
                "    rating_matrix_dense = None\n",
                "    use_dense = False"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Matrix Factorization Methods"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def perform_svd_factorization(matrix, k=50):\n",
                "    \"\"\"\n",
                "    Perform SVD factorization on the rating matrix\n",
                "    Returns U, sigma, Vt where matrix ‚âà U @ diag(sigma) @ Vt\n",
                "    \"\"\"\n",
                "    print(f\"\\nPerforming SVD with k={k} factors...\")\n",
                "    \n",
                "    if matrix.shape[1] <= k:\n",
                "        k = matrix.shape[1] - 1\n",
                "        print(f\"Reduced k to {k} due to matrix dimensions\")\n",
                "    \n",
                "    # Use sparse SVD\n",
                "    U, sigma, Vt = svds(matrix, k=k)\n",
                "    \n",
                "    # Sort by singular values (descending)\n",
                "    idx = np.argsort(sigma)[::-1]\n",
                "    U = U[:, idx]\n",
                "    sigma = sigma[idx]\n",
                "    Vt = Vt[idx, :]\n",
                "    \n",
                "    print(f\"SVD completed:\")\n",
                "    print(f\"  U shape: {U.shape} (users √ó factors)\")\n",
                "    print(f\"  Sigma shape: {sigma.shape} (singular values)\")\n",
                "    print(f\"  Vt shape: {Vt.shape} (factors √ó books)\")\n",
                "    print(f\"  Top 5 singular values: {sigma[:5]}\")\n",
                "    \n",
                "    return U, sigma, Vt\n",
                "\n",
                "def perform_nmf_factorization(matrix, k=50, max_iter=200):\n",
                "    \"\"\"\n",
                "    Perform Non-negative Matrix Factorization\n",
                "    Returns W, H where matrix ‚âà W @ H\n",
                "    \"\"\"\n",
                "    print(f\"\\nPerforming NMF with k={k} factors...\")\n",
                "    \n",
                "    # NMF requires non-negative values, so we'll work with the dense matrix\n",
                "    if use_dense:\n",
                "        matrix_input = rating_matrix_dense\n",
                "    else:\n",
                "        print(\"Converting sparse matrix to dense for NMF...\")\n",
                "        matrix_input = matrix.toarray()\n",
                "    \n",
                "    # Ensure non-negative (ratings should already be non-negative)\n",
                "    matrix_input = np.maximum(matrix_input, 0)\n",
                "    \n",
                "    nmf = NMF(n_components=k, max_iter=max_iter, random_state=42, alpha_W=0.1, alpha_H=0.1)\n",
                "    W = nmf.fit_transform(matrix_input)  # Users √ó factors\n",
                "    H = nmf.components_  # Factors √ó books\n",
                "    \n",
                "    print(f\"NMF completed:\")\n",
                "    print(f\"  W shape: {W.shape} (users √ó factors)\")\n",
                "    print(f\"  H shape: {H.shape} (factors √ó books)\")\n",
                "    print(f\"  Reconstruction error: {nmf.reconstruction_err_:.4f}\")\n",
                "    print(f\"  Iterations: {nmf.n_iter_}\")\n",
                "    \n",
                "    return W, H, nmf\n",
                "\n",
                "def reconstruct_matrix(U=None, sigma=None, Vt=None, W=None, H=None, method='svd'):\n",
                "    \"\"\"\n",
                "    Reconstruct the rating matrix from factorization\n",
                "    \"\"\"\n",
                "    if method == 'svd':\n",
                "        return U @ np.diag(sigma) @ Vt\n",
                "    elif method == 'nmf':\n",
                "        return W @ H\n",
                "    else:\n",
                "        raise ValueError(\"Method must be 'svd' or 'nmf'\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Perform both SVD and NMF factorizations\n",
                "k_factors = 50  # Number of latent factors\n",
                "\n",
                "# SVD Factorization\n",
                "U_svd, sigma_svd, Vt_svd = perform_svd_factorization(rating_matrix, k=k_factors)\n",
                "\n",
                "# NMF Factorization  \n",
                "W_nmf, H_nmf, nmf_model = perform_nmf_factorization(rating_matrix, k=k_factors)\n",
                "\n",
                "# Compute reconstruction errors\n",
                "print(\"\\n=== Reconstruction Analysis ===\")\n",
                "\n",
                "# For SVD\n",
                "reconstructed_svd = reconstruct_matrix(U_svd, sigma_svd, Vt_svd, method='svd')\n",
                "if use_dense:\n",
                "    # Only compute for non-zero entries (where we have actual ratings)\n",
                "    mask = rating_matrix_dense > 0\n",
                "    svd_error = np.mean((rating_matrix_dense[mask] - reconstructed_svd[mask]) ** 2)\n",
                "    print(f\"SVD RMSE on observed ratings: {np.sqrt(svd_error):.4f}\")\n",
                "\n",
                "# For NMF\n",
                "reconstructed_nmf = reconstruct_matrix(W=W_nmf, H=H_nmf, method='nmf')\n",
                "if use_dense:\n",
                "    nmf_error = np.mean((rating_matrix_dense[mask] - reconstructed_nmf[mask]) ** 2)\n",
                "    print(f\"NMF RMSE on observed ratings: {np.sqrt(nmf_error):.4f}\")\n",
                "\n",
                "# Analyze the factors\n",
                "print(f\"\\nFactor Analysis:\")\n",
                "print(f\"SVD - Explained variance ratio: {(sigma_svd**2).cumsum() / (sigma_svd**2).sum()}\")\n",
                "print(f\"NMF - Factor magnitudes: {np.linalg.norm(H_nmf, axis=1)[:10]}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Book Similarity Analysis"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def compute_book_similarities(method='svd'):\n",
                "    \"\"\"\n",
                "    Compute book similarities using the factorized representations\n",
                "    \n",
                "    For SVD: books are represented by Vt.T (books √ó factors)\n",
                "    For NMF: books are represented by H.T (books √ó factors)\n",
                "    \"\"\"\n",
                "    print(f\"\\n=== Computing Book Similarities using {method.upper()} ===\")\n",
                "    \n",
                "    if method == 'svd':\n",
                "        # Books are columns, so we transpose Vt to get (books √ó factors)\n",
                "        book_factors = Vt_svd.T\n",
                "    elif method == 'nmf':\n",
                "        # H is (factors √ó books), so transpose to get (books √ó factors)\n",
                "        book_factors = H_nmf.T\n",
                "    else:\n",
                "        raise ValueError(\"Method must be 'svd' or 'nmf'\")\n",
                "    \n",
                "    print(f\"Book factors shape: {book_factors.shape}\")\n",
                "    \n",
                "    # Compute cosine similarity between all book pairs\n",
                "    book_similarity_matrix = cosine_similarity(book_factors)\n",
                "    \n",
                "    print(f\"Book similarity matrix shape: {book_similarity_matrix.shape}\")\n",
                "    print(f\"Similarity range: [{book_similarity_matrix.min():.3f}, {book_similarity_matrix.max():.3f}]\")\n",
                "    \n",
                "    # Remove self-similarities for analysis\n",
                "    np.fill_diagonal(book_similarity_matrix, 0)\n",
                "    non_diag_similarities = book_similarity_matrix[book_similarity_matrix != 0]\n",
                "    \n",
                "    print(f\"Non-diagonal similarity stats:\")\n",
                "    print(f\"  Mean: {non_diag_similarities.mean():.4f}\")\n",
                "    print(f\"  Std: {non_diag_similarities.std():.4f}\")\n",
                "    print(f\"  95th percentile: {np.percentile(non_diag_similarities, 95):.4f}\")\n",
                "    \n",
                "    return book_similarity_matrix, book_factors\n",
                "\n",
                "# Compute similarities for both methods\n",
                "book_sim_svd, book_factors_svd = compute_book_similarities('svd')\n",
                "book_sim_nmf, book_factors_nmf = compute_book_similarities('nmf')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Recommendation Functions"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "class BookRecommender:\n",
                "    def __init__(self, similarity_matrix, book_factors, method_name):\n",
                "        self.similarity_matrix = similarity_matrix\n",
                "        self.book_factors = book_factors\n",
                "        self.method_name = method_name\n",
                "        \n",
                "    def find_similar_books(self, book_title, k=10):\n",
                "        \"\"\"\n",
                "        Find k most similar books to the given book title\n",
                "        \"\"\"\n",
                "        # Check if book exists\n",
                "        if book_title not in title_to_idx:\n",
                "            return self._suggest_similar_titles(book_title)\n",
                "        \n",
                "        book_idx = title_to_idx[book_title]\n",
                "        \n",
                "        # Get similarity scores for this book\n",
                "        similarities = self.similarity_matrix[book_idx]\n",
                "        \n",
                "        # Get top k most similar books (excluding the book itself)\n",
                "        top_indices = np.argsort(similarities)[::-1][:k]\n",
                "        \n",
                "        recommendations = []\n",
                "        for idx in top_indices:\n",
                "            if idx != book_idx:  # Skip the book itself\n",
                "                try:\n",
                "                    title = idx_to_title[idx]\n",
                "                    author = idx_to_author.get(idx, \"Unknown Author\")\n",
                "                    similarity = similarities[idx]\n",
                "                    recommendations.append((title, author, similarity))\n",
                "                except KeyError:\n",
                "                    continue\n",
                "        \n",
                "        return recommendations[:k]\n",
                "    \n",
                "    def _suggest_similar_titles(self, book_title):\n",
                "        \"\"\"\n",
                "        Suggest similar titles if exact match not found\n",
                "        \"\"\"\n",
                "        query_lower = book_title.lower()\n",
                "        matches = []\n",
                "        \n",
                "        for title in title_to_idx.keys():\n",
                "            if query_lower in title.lower():\n",
                "                book_idx = title_to_idx[title]\n",
                "                author = idx_to_author.get(book_idx, \"Unknown Author\")\n",
                "                matches.append((title, author))\n",
                "        \n",
                "        if matches:\n",
                "            print(f\"Book '{book_title}' not found. Did you mean one of these?\")\n",
                "            for i, (title, author) in enumerate(matches[:5], 1):\n",
                "                print(f\"  {i}. {title} by {author}\")\n",
                "        else:\n",
                "            print(f\"Book '{book_title}' not found in the dataset.\")\n",
                "        \n",
                "        return []\n",
                "    \n",
                "    def search_books(self, query, max_results=10):\n",
                "        \"\"\"\n",
                "        Search for books by title (partial matching)\n",
                "        \"\"\"\n",
                "        query_lower = query.lower()\n",
                "        matches = []\n",
                "        \n",
                "        for title in title_to_idx.keys():\n",
                "            if query_lower in title.lower():\n",
                "                book_idx = title_to_idx[title]\n",
                "                author = idx_to_author.get(book_idx, \"Unknown Author\")\n",
                "                matches.append((title, author))\n",
                "        \n",
                "        return matches[:max_results]\n",
                "    \n",
                "    def display_recommendations(self, book_title, recommendations, k=10):\n",
                "        \"\"\"\n",
                "        Display recommendations in a nice format\n",
                "        \"\"\"\n",
                "        if not recommendations:\n",
                "            return\n",
                "        \n",
                "        # Get info about the query book\n",
                "        if book_title in title_to_idx:\n",
                "            query_idx = title_to_idx[book_title]\n",
                "            query_author = idx_to_author.get(query_idx, \"Unknown Author\")\n",
                "            print(f\"\\nüìö Books similar to: '{book_title}' by {query_author}\")\n",
                "            print(f\"Using {self.method_name} factorization\")\n",
                "        else:\n",
                "            print(f\"\\nüìö Books similar to: '{book_title}'\")\n",
                "        \n",
                "        print(\"=\" * 80)\n",
                "        \n",
                "        for i, (title, author, similarity) in enumerate(recommendations[:k], 1):\n",
                "            print(f\"{i:2d}. {title}\")\n",
                "            print(f\"    by {author}\")\n",
                "            print(f\"    Similarity: {similarity:.3f}\")\n",
                "            print()\n",
                "    \n",
                "    def get_book_vector(self, book_title):\n",
                "        \"\"\"\n",
                "        Get the factor vector for a specific book\n",
                "        \"\"\"\n",
                "        if book_title not in title_to_idx:\n",
                "            print(f\"Book '{book_title}' not found\")\n",
                "            return None\n",
                "        \n",
                "        book_idx = title_to_idx[book_title]\n",
                "        return self.book_factors[book_idx]\n",
                "\n",
                "# Create recommender instances\n",
                "recommender_svd = BookRecommender(book_sim_svd, book_factors_svd, \"SVD\")\n",
                "recommender_nmf = BookRecommender(book_sim_nmf, book_factors_nmf, \"NMF\")\n",
                "\n",
                "print(\"\\n‚úÖ Recommendation systems ready!\")\n",
                "print(\"Available recommenders: recommender_svd, recommender_nmf\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Test Recommendations"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Test with some popular books\n",
                "test_queries = [\n",
                "    \"Harry Potter\",\n",
                "    \"Lord of the Rings\", \n",
                "    \"To Kill a Mockingbird\",\n",
                "    \"1984\",\n",
                "    \"Pride and Prejudice\"\n",
                "]\n",
                "\n",
                "for query in test_queries:\n",
                "    print(f\"\\n{'='*60}\")\n",
                "    print(f\"Searching for: {query}\")\n",
                "    \n",
                "    # Search for books matching the query\n",
                "    matches = recommender_svd.search_books(query, max_results=3)\n",
                "    \n",
                "    if matches:\n",
                "        print(f\"\\nFound {len(matches)} matching books:\")\n",
                "        for i, (title, author) in enumerate(matches, 1):\n",
                "            print(f\"  {i}. {title} by {author}\")\n",
                "        \n",
                "        # Use the first match for recommendations\n",
                "        sample_book = matches[0][0]\n",
                "        print(f\"\\nGetting recommendations for: {sample_book}\")\n",
                "        \n",
                "        # Get recommendations from both methods\n",
                "        recs_svd = recommender_svd.find_similar_books(sample_book, k=5)\n",
                "        recs_nmf = recommender_nmf.find_similar_books(sample_book, k=5)\n",
                "        \n",
                "        if recs_svd:\n",
                "            print(f\"\\n--- SVD Recommendations ---\")\n",
                "            for i, (title, author, sim) in enumerate(recs_svd, 1):\n",
                "                print(f\"{i}. {title} by {author} (sim: {sim:.3f})\")\n",
                "        \n",
                "        if recs_nmf:\n",
                "            print(f\"\\n--- NMF Recommendations ---\")\n",
                "            for i, (title, author, sim) in enumerate(recs_nmf, 1):\n",
                "                print(f\"{i}. {title} by {author} (sim: {sim:.3f})\")\n",
                "    else:\n",
                "        print(f\"No books found matching '{query}'\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Detailed Example: Harry Potter Recommendations"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Find a Harry Potter book for detailed analysis\n",
                "harry_potter_books = recommender_svd.search_books(\"harry potter\", max_results=10)\n",
                "\n",
                "if harry_potter_books:\n",
                "    print(\"Harry Potter books in dataset:\")\n",
                "    for i, (title, author) in enumerate(harry_potter_books, 1):\n",
                "        print(f\"  {i}. {title} by {author}\")\n",
                "    \n",
                "    # Use the first one for detailed recommendations\n",
                "    hp_book = harry_potter_books[0][0]\n",
                "    \n",
                "    print(f\"\\n{'='*80}\")\n",
                "    print(f\"DETAILED ANALYSIS: {hp_book}\")\n",
                "    print(f\"{'='*80}\")\n",
                "    \n",
                "    # Get recommendations from both methods\n",
                "    svd_recs = recommender_svd.find_similar_books(hp_book, k=10)\n",
                "    nmf_recs = recommender_nmf.find_similar_books(hp_book, k=10)\n",
                "    \n",
                "    # Display SVD recommendations\n",
                "    print(\"\\nüîç SVD-based Recommendations:\")\n",
                "    recommender_svd.display_recommendations(hp_book, svd_recs)\n",
                "    \n",
                "    # Display NMF recommendations\n",
                "    print(\"\\nüîç NMF-based Recommendations:\")\n",
                "    recommender_nmf.display_recommendations(hp_book, nmf_recs)\n",
                "    \n",
                "    # Compare the factor representations\n",
                "    svd_vector = recommender_svd.get_book_vector(hp_book)\n",
                "    nmf_vector = recommender_nmf.get_book_vector(hp_book)\n",
                "    \n",
                "    print(f\"\\nüìä Factor Analysis for '{hp_book}':\")\n",
                "    print(f\"SVD vector norm: {np.linalg.norm(svd_vector):.3f}\")\n",
                "    print(f\"NMF vector norm: {np.linalg.norm(nmf_vector):.3f}\")\n",
                "    print(f\"Top 5 SVD factors: {svd_vector[:5]}\")\n",
                "    print(f\"Top 5 NMF factors: {nmf_vector[:5]}\")\n",
                "\n",
                "else:\n",
                "    print(\"No Harry Potter books found in the dataset\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Visualization and Analysis"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Visualize similarity distributions\n",
                "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
                "\n",
                "# SVD similarity distribution\n",
                "svd_similarities = book_sim_svd[book_sim_svd != 0].flatten()\n",
                "axes[0,0].hist(svd_similarities, bins=50, alpha=0.7, edgecolor='black')\n",
                "axes[0,0].set_title('SVD: Book Similarity Distribution')\n",
                "axes[0,0].set_xlabel('Cosine Similarity')\n",
                "axes[0,0].set_ylabel('Frequency')\n",
                "axes[0,0].grid(True, alpha=0.3)\n",
                "\n",
                "# NMF similarity distribution\n",
                "nmf_similarities = book_sim_nmf[book_sim_nmf != 0].flatten()\n",
                "axes[0,1].hist(nmf_similarities, bins=50, alpha=0.7, edgecolor='black', color='orange')\n",
                "axes[0,1].set_title('NMF: Book Similarity Distribution')\n",
                "axes[0,1].set_xlabel('Cosine Similarity')\n",
                "axes[0,1].set_ylabel('Frequency')\n",
                "axes[0,1].grid(True, alpha=0.3)\n",
                "\n",
                "# Singular values for SVD\n",
                "axes[1,0].plot(sigma_svd, 'o-', alpha=0.7)\n",
                "axes[1,0].set_title('SVD: Singular Values')\n",
                "axes[1,0].set_xlabel('Factor Index')\n",
                "axes[1,0].set_ylabel('Singular Value')\n",
                "axes[1,0].set_yscale('log')\n",
                "axes[1,0].grid(True, alpha=0.3)\n",
                "\n",
                "# Factor magnitudes for NMF\n",
                "nmf_factor_norms = np.linalg.norm(H_nmf, axis=1)\n",
                "axes[1,1].plot(nmf_factor_norms, 'o-', alpha=0.7, color='orange')\n",
                "axes[1,1].set_title('NMF: Factor Magnitudes')\n",
                "axes[1,1].set_xlabel('Factor Index')\n",
                "axes[1,1].set_ylabel('L2 Norm')\n",
                "axes[1,1].grid(True, alpha=0.3)\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.show()\n",
                "\n",
                "# Log to wandb\n",
                "wandb.log({\"analysis_plots\": wandb.Image(plt)})\n",
                "\n",
                "# Print comparison statistics\n",
                "print(\"\\nüìä Method Comparison:\")\n",
                "print(f\"SVD similarities - Mean: {svd_similarities.mean():.4f}, Std: {svd_similarities.std():.4f}\")\n",
                "print(f\"NMF similarities - Mean: {nmf_similarities.mean():.4f}, Std: {nmf_similarities.std():.4f}\")\n",
                "# print(f\"\\nSVD explained variance (top 10): {(sigma_svd[:10]**2 / np.sum(sigma_svd**2) * 100):.1f}%\")\n",
                "print(f\"NMF reconstruction error: {nmf_model.reconstruction_err_:.4f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Find Most Similar Book Pairs"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def find_most_similar_pairs(similarity_matrix, method_name, top_k=10):\n",
                "    \"\"\"\n",
                "    Find the most similar book pairs\n",
                "    \"\"\"\n",
                "    print(f\"\\nüîç Most Similar Book Pairs ({method_name}):\")\n",
                "    print(\"=\" * 60)\n",
                "    \n",
                "    # Get upper triangle (avoid duplicates and self-similarities)\n",
                "    similarity_pairs = []\n",
                "    for i in range(len(similarity_matrix)):\n",
                "        for j in range(i+1, len(similarity_matrix)):\n",
                "            similarity_pairs.append((i, j, similarity_matrix[i, j]))\n",
                "    \n",
                "    # Sort by similarity (descending)\n",
                "    similarity_pairs.sort(key=lambda x: x[2], reverse=True)\n",
                "    \n",
                "    for rank, (book1_idx, book2_idx, similarity) in enumerate(similarity_pairs[:top_k], 1):\n",
                "        try:\n",
                "            title1 = idx_to_title[book1_idx]\n",
                "            title2 = idx_to_title[book2_idx]\n",
                "            author1 = idx_to_author.get(book1_idx, \"Unknown\")\n",
                "            author2 = idx_to_author.get(book2_idx, \"Unknown\")\n",
                "            \n",
                "            print(f\"{rank:2d}. Similarity: {similarity:.3f}\")\n",
                "            print(f\"    üìñ {title1}\")\n",
                "            print(f\"       by {author1}\")\n",
                "            print(f\"    üìñ {title2}\")\n",
                "            print(f\"       by {author2}\")\n",
                "            print()\n",
                "        except KeyError:\n",
                "            continue\n",
                "\n",
                "# Find most similar pairs for both methods\n",
                "find_most_similar_pairs(book_sim_svd, \"SVD\", top_k=10)\n",
                "find_most_similar_pairs(book_sim_nmf, \"NMF\", top_k=10)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Interactive Recommendation Function"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def interactive_recommendations():\n",
                "    \"\"\"\n",
                "    Interactive function for book recommendations\n",
                "    \"\"\"\n",
                "    print(\"\\nüéØ Interactive Book Recommendation System\")\n",
                "    print(\"Commands:\")\n",
                "    print(\"  - Type a book title to get recommendations\")\n",
                "    print(\"  - 'search <query>' to search for books\")\n",
                "    print(\"  - 'method svd' or 'method nmf' to switch methods\")\n",
                "    print(\"  - 'quit' to exit\")\n",
                "    print(\"=\" * 60)\n",
                "    \n",
                "    current_recommender = recommender_svd  # Default to SVD\n",
                "    \n",
                "    while True:\n",
                "        user_input = input(f\"\\n[{current_recommender.method_name}] Enter command: \").strip()\n",
                "        \n",
                "        if user_input.lower() == 'quit':\n",
                "            print(\"Goodbye! üìö\")\n",
                "            break\n",
                "        \n",
                "        if user_input.lower().startswith('search '):\n",
                "            query = user_input[7:]  # Remove 'search ' prefix\n",
                "            matches = current_recommender.search_books(query, max_results=10)\n",
                "            if matches:\n",
                "                print(f\"\\nüîç Found {len(matches)} books matching '{query}':\")\n",
                "                for i, (title, author) in enumerate(matches, 1):\n",
                "                    print(f\"  {i:2d}. {title} by {author}\")\n",
                "            else:\n",
                "                print(f\"‚ùå No books found matching '{query}'\")\n",
                "            continue\n",
                "        \n",
                "        if user_input.lower().startswith('method '):\n",
                "            method = user_input[7:].lower()\n",
                "            if method == 'svd':\n",
                "                current_recommender = recommender_svd\n",
                "                print(\"‚úÖ Switched to SVD method\")\n",
                "            elif method == 'nmf':\n",
                "                current_recommender = recommender_nmf\n",
                "                print(\"‚úÖ Switched to NMF method\")\n",
                "            else:\n",
                "                print(\"‚ùå Unknown method. Use 'svd' or 'nmf'\")\n",
                "            continue\n",
                "        \n",
                "        # Try to get recommendations\n",
                "        recommendations = current_recommender.find_similar_books(user_input, k=8)\n",
                "        current_recommender.display_recommendations(user_input, recommendations, k=8)\n",
                "\n",
                "# Uncomment to run interactive session\n",
                "# interactive_recommendations()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Save Results"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Save the factorization results and mappings\n",
                "print(\"\\n=== Saving Results ===\")\n",
                "\n",
                "import pickle\n",
                "\n",
                "# Save SVD results\n",
                "np.savez_compressed('matrix_factorization_svd.npz',\n",
                "                   U=U_svd,\n",
                "                   sigma=sigma_svd, \n",
                "                   Vt=Vt_svd,\n",
                "                   book_similarity=book_sim_svd,\n",
                "                   book_factors=book_factors_svd)\n",
                "\n",
                "# Save NMF results\n",
                "np.savez_compressed('matrix_factorization_nmf.npz',\n",
                "                   W=W_nmf,\n",
                "                   H=H_nmf,\n",
                "                   book_similarity=book_sim_nmf,\n",
                "                   book_factors=book_factors_nmf)\n",
                "\n",
                "# Save mappings and metadata\n",
                "mappings = {\n",
                "    'title_to_idx': title_to_idx,\n",
                "    'idx_to_title': idx_to_title,\n",
                "    'idx_to_author': idx_to_author,\n",
                "    'book_to_idx': book_to_idx,\n",
                "    'idx_to_book': idx_to_book,\n",
                "    'user_to_idx': user_to_idx,\n",
                "    'idx_to_user': idx_to_user,\n",
                "    'n_users': n_users,\n",
                "    'n_books': n_books,\n",
                "    'k_factors': k_factors\n",
                "}\n",
                "\n",
                "with open('matrix_factorization_mappings.pkl', 'wb') as f:\n",
                "    pickle.dump(mappings, f)\n",
                "\n",
                "# Save the rating matrix\n",
                "from scipy.sparse import save_npz\n",
                "save_npz('rating_matrix.npz', rating_matrix)\n",
                "\n",
                "print(\"‚úÖ Saved:\")\n",
                "print(\"  - matrix_factorization_svd.npz\")\n",
                "print(\"  - matrix_factorization_nmf.npz\")\n",
                "print(\"  - matrix_factorization_mappings.pkl\")\n",
                "print(\"  - rating_matrix.npz\")\n",
                "\n",
                "print(f\"\\nüìä Final Summary:\")\n",
                "print(f\"  Users: {n_users:,}\")\n",
                "print(f\"  Books: {n_books:,}\")\n",
                "print(f\"  Ratings: {len(filtered_ratings):,}\")\n",
                "print(f\"  Sparsity: {(1 - len(filtered_ratings) / (n_users * n_books)) * 100:.2f}%\")\n",
                "print(f\"  Factors: {k_factors}\")\n",
                "print(f\"  SVD reconstruction quality: RMSE = {np.sqrt(svd_error):.4f}\" if use_dense else \"\")\n",
                "print(f\"  NMF reconstruction error: {nmf_model.reconstruction_err_:.4f}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Finish wandb run\n",
                "wandb.log({\n",
                "    'final_metrics': {\n",
                "        'n_users': n_users,\n",
                "        'n_books': n_books,\n",
                "        'n_ratings': len(filtered_ratings),\n",
                "        'sparsity': (1 - len(filtered_ratings) / (n_users * n_books)) * 100,\n",
                "        'k_factors': k_factors,\n",
                "        'svd_explained_variance_top10': (sigma_svd[:10]**2).sum() / (sigma_svd**2).sum() * 100,\n",
                "        'nmf_reconstruction_error': nmf_model.reconstruction_err_\n",
                "    }\n",
                "})\n",
                "\n",
                "run.finish()"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": ".venv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.3"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
